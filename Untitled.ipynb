{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0de458f-c6c7-4b54-85b0-aa08022a9b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversion complete.\n",
      "Rows: 84465\n",
      "         transcript_id  time_of_interaction               domain  \\\n",
      "0  6794-8660-4606-3216  2025-10-03 20:22:00  E-commerce & Retail   \n",
      "1  6794-8660-4606-3216  2025-10-03 20:22:00  E-commerce & Retail   \n",
      "2  6794-8660-4606-3216  2025-10-03 20:22:00  E-commerce & Retail   \n",
      "3  6794-8660-4606-3216  2025-10-03 20:22:00  E-commerce & Retail   \n",
      "4  6794-8660-4606-3216  2025-10-03 20:22:00  E-commerce & Retail   \n",
      "\n",
      "                   intent                                    reason_for_call  \\\n",
      "0  Delivery Investigation  Customer James Bailey reported a smart watch s...   \n",
      "1  Delivery Investigation  Customer James Bailey reported a smart watch s...   \n",
      "2  Delivery Investigation  Customer James Bailey reported a smart watch s...   \n",
      "3  Delivery Investigation  Customer James Bailey reported a smart watch s...   \n",
      "4  Delivery Investigation  Customer James Bailey reported a smart watch s...   \n",
      "\n",
      "  outcome_label  turn_id   speaker  \\\n",
      "0       unknown        0     Agent   \n",
      "1       unknown        1  Customer   \n",
      "2       unknown        2     Agent   \n",
      "3       unknown        3  Customer   \n",
      "4       unknown        4     Agent   \n",
      "\n",
      "                                                text  \n",
      "0  Hello, thank you for contacting BuyNow. This i...  \n",
      "1  Hello, I'm calling about an order that shows d...  \n",
      "2  I'm sorry to hear that. I'll definitely help y...  \n",
      "3  It's 9595912. The tracking was marked delivere...  \n",
      "4  Let me pull that up right away. Okay, I see th...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON\n",
    "with open(\"C:/Users/adityaacer7/Desktop/Pravahh/Conversational_Transcript_Dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- auto-detect structure ---\n",
    "if isinstance(data, dict):\n",
    "    # find first list inside dict\n",
    "    for v in data.values():\n",
    "        if isinstance(v, list):\n",
    "            data = v\n",
    "            break\n",
    "    else:\n",
    "        data = [data]  # single transcript fallback\n",
    "\n",
    "rows = []\n",
    "\n",
    "for convo in data:\n",
    "    transcript_id = str(convo.get(\"transcript_id\", \"unknown\"))\n",
    "\n",
    "    base = {\n",
    "        \"transcript_id\": transcript_id,\n",
    "        \"time_of_interaction\": convo.get(\"time_of_interaction\", \"\"),\n",
    "        \"domain\": convo.get(\"domain\", \"\"),\n",
    "        \"intent\": convo.get(\"intent\", \"\"),\n",
    "        \"reason_for_call\": convo.get(\"reason_for_call\", \"\"),\n",
    "        \"outcome_label\": convo.get(\"outcome\", \"unknown\")\n",
    "    }\n",
    "\n",
    "    turns = convo.get(\"conversation\", [])\n",
    "\n",
    "    for i, turn in enumerate(turns):\n",
    "        rows.append({\n",
    "            **base,\n",
    "            \"turn_id\": i,\n",
    "            \"speaker\": turn.get(\"speaker\", \"\"),\n",
    "            \"text\": turn.get(\"text\", \"\")\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.to_csv(\"structured_transcripts.csv\", index=False)\n",
    "\n",
    "print(\"✅ Conversion complete.\")\n",
    "print(\"Rows:\", len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c8b93c2-ca23-47b7-aceb-48a425058068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adityaacer7\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\adityaacer7\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adityaacer7\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 698.01it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Indexed with Chroma\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "df = pd.read_csv(\"structured_transcripts.csv\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"transcripts\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    emb = model.encode(row[\"text\"]).tolist()\n",
    "\n",
    "    collection.add(\n",
    "        ids=[str(i)],\n",
    "        embeddings=[emb],\n",
    "        documents=[row[\"text\"]],\n",
    "        metadatas=[{\n",
    "            \"transcript_id\": row[\"transcript_id\"],\n",
    "            \"speaker\": row[\"speaker\"]\n",
    "        }]\n",
    "    )\n",
    "\n",
    "print(\"✅ Indexed with Chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ac085-4fd0-44aa-b7a8-1e641d485467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
